\documentclass{article}
\usepackage{import}
\usepackage[ruled]{algorithm2e}
\usepackage[shortlabels]{enumitem}
\usepackage{hyperref}
\usepackage{minted}
\usepackage{subcaption}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }
\subimport*{}{macro}

\setlength\parindent{0px}

\begin{document}
\setcounter{problem}{0}
\title{Homework \#5}
\author{
    \normalsize{AA 597: Networked Dynamics Systems}\\
    \normalsize{Prof. Mehran Mesbahi}\\
    \normalsize{Due: Feb 16, 2024 11:59pm}\\
    \normalsize{Soowhan Yi}
}
\date{{}}
\maketitle

All the codes are available at the end of the documents or here.
\url{https://github.com/SoowhanYi94/ME597}
\begin{problem}7.1
    This chapter mainly dealt with $\Delta$-disk graphs, that is, proximity graph (V,E) such that ${v_i, v_j} \in E$ if and only if $||x_i - x_j|| \leq \Delta$. wjere $x_i \in R^p, i = 1, \cdots, n, $ is the state of robot i. In this exercise, we will be exploring another type of proximity graphy, namely the wedge graph. Assume that instead of single integrator dynamics, the agents' dynamics are defined as unicycle robots, that is, 
    \begin{align*}
        &\dot x_i(t) = v_i(t) cos{\phi_i (t)}\\
        &\dot y_i(t) = v_i(t) sin{\phi_i (t)}\\
        &\dot \phi_i(t)= \omega_i(t)
    \end{align*}
    
    Here $[x_i, y_i]^T$ is the position of robot i, while, $\phi_i$ denotes its orientation. Moreover, $v_i$ and $\omega_i$ are the translational and rotational velocities, which are the controlled inputs. Now, assume that such a robot is equiopped with a rigidly mounted camer, facing in the forward direction. This gives rise to a directed wedge graph, as seen in the figure. For such a setup, if robot j is visible from robot i, the available information is $d_{ij} = ||[x_i, y_i]^T - [x_j, y_j]^T||$ (distance between agents) and $\delta \phi_{ij}$(relative interagent angle) as per the figure below. Explain how you would solve the rendezvous (agreement) problem for such a system. 
    
    \vspace{12pt}
    In order to solve this agreement problem, we need to controll the distance between two agents, especially between the leaf nodes($v_j$ and $v_k$ in the example) and the center node($v_i$), and angle between them. We have a sector form of sensing area, and we need to keep them inside in order to stay connected. So we construct a potential function of $V_i = \sum_{j \in N(i) }(\frac{1}{(\delta \phi_{ij} - \frac{\Delta \psi}{2})^2} + \frac{d_{ij}^2}{\rho - d_{ij}})$. Then, 
    \begin{align*}
        v_i(t)&=\dot r_i(t) = \sum_{j \in N(i) }-\frac{dV_{i}}{d (d_{ij})}= -\sum_{j \in N(i) }\frac{2\rho  - ||d_{ij}||}{(\rho  - ||d_{ij} ||)^2} (r_{i} - r_{j} ) \\
        \dot x_i(t) &= -\sum_{j \in N(i) }\frac{2\rho  - ||d_{ij}||}{(\rho  - ||d_{ij} ||)^2} (r_{i} - r_{j} ) \cos(\delta \phi_{ij})\\
        \dot y_i(t) &= -\sum_{j \in N(i) }\frac{2\rho  - ||d_{ij}||}{(\rho  - ||d_{ij} ||)^2} (r_{i} - r_{j} ) \sin(\delta \phi_{ij})
    \end{align*}
    where this i corresponds to those robot agents. Lemma 7.1 from textbook proves that $\Omega (\rho, r_0) = \curly{r| V(\rho, r) \leq V(\rho, r_0)}$ is invariant set under the above control law, where $r_0 \in D_{G, \rho} ^\epsilon$ for $\epsilon \in (0, \rho)$. Also the theorem 7.2 from textbook proves that this control law asymptotically converges to the static centroid. 

    Now we need to keep the angles between them to be in certain range, and I would use the same logic that was used in above equation.
    \begin{align*}
        \omega_i = \dot {\delta \phi_{ij}}(t) &= - \sum_{j \in N(i) }\frac{-2}{( \delta \phi_{ij}-\frac{\Delta \psi}{2})^3} 
    \end{align*}
    With above equations, agents are guranteed to stay in the sector shaped sensing area. Since we have $\delta \phi_{ij}^0 \leq \frac{\Delta \psi}{2}$, this $\delta \phi_{ij}(t)$ would never increase. Therefore angle between them would never increase and distance would converge to their static centroid. 


\end{problem}
\begin{problem}
Show that if a $\delta$-disk proximity graph with 4 agents starts connected, then, using the linear agreement protocol, it stays connected for all times.

With theorem 3.4  in the textbook, we know that the linear agreement protocol converges to the agreement set. Therefore the length of edges between two vertices would never increase. Even with the case where 2 nodes (node 1 and node 2)are located in one points $\Delta$ away from node 3, and node 4 is located $\Delta$ away from node 3 and $2 \Delta$ away from node 1 and 2, we proved that they do converge in one point with 4 agents from last homework(4.8). As we have started with each lengths of edges being less than or equal to $\Delta$, those lengths would stay less than $\Delta$ in the progress of the linear agreement protocol and until it reaches the agreement. 


\end{problem}
\begin{problem}
    \begin{align*}
        \dot x_i(t) &= -\sum_{j \in N_{G_d}(i)} \frac{2(\Delta - ||d_{ij}||) - ||l_{ij} - d_{ij}||}{(\Delta - ||d_{ij}|| - ||l_{ij} - d_{ij}||)^2} (x_i(t) - x_j(t) - d_{ij} )
    \end{align*}
    Lemma 7.5\\
    Given an initial conditions $x_0$ such that $y_0 = (x_0 - \tau_0) \in D_{G_{d}, \Delta -||d||}^\epsilon$, with $G_d$ a connected spanning graph of $G(x_0)$, the group of autonomous mobile agents adopting the decentralized contral law (the equation above) are guranteed to satisfy
    \begin{align*}
        ||x_i(t) - x_j(t)|| = ||l_{ij}(t)|| \leq \Delta \text{ for all } t > 0 \text{ and }{ v_i, v_j} \in E_d
    \end{align*}

    Theorem 7.6
    Under the same assumptions as in Lemma 7.5, for all i, j, the pairwize relative distants $||l_{ij}|| = ||x_i(t) - x_j(t)||$ asymptotically converge to $||d_{ij}||$ for ${v_i, v_j} \in E_d$
    
    \vspace{12pt}
    Implement the algorithm above and explore how the conditions of Lemma 7.5/Thm 7.6 are required for the algorithm to work as proposed.
    \begin{figure*}[!h]
        \centering
        \begin{subfigure}{0.3\textwidth}
            \includegraphics[width=\textwidth]{./img/p3_1.png}
            \caption{$||x_i - x_j|| \leq \Delta$}
        \end{subfigure}
        \begin{subfigure}{0.3\textwidth}
            \includegraphics[width=\textwidth]{./img/p3_2.png}
            \caption{$||x_i - x_j|| \nleq \Delta$}
        \end{subfigure}
        \begin{subfigure}{0.3\textwidth}
            \includegraphics[width=\textwidth]{./img/p3_3.png}
            \caption{$||x_4 - x_j|| \nleq \Delta$ }
        \end{subfigure}
    \end{figure*}

    For above graphs, the desired lengths between each nodes are set to be 0 for simplicity. As we can see from above results, when those initial conditions satisfy those conditions of Lemma 7.5 and theorem 7.6, above algorithm asymptotically converges to edge length of 0. Also, those that are not satisfing those conditions ($x_0, x_3, x_4$ in (b), and $x_4$ in (c)) are diverging and those that are satisfing conditions ($x_1, x_2$ in (b), and $x_0, x_1, x_2, x_3$ in(c)) are converging. Also, when $||x_i - x_j|| = \Delta$, above algorithm does not compute because we would be getting infinite number when the desired length for edges are 0. So we need this threshold $\epsilon$ for computation. Therefore this algorithm, in order to work properly, those conditions of Lemma 7.5 and theorem 7.6 are required. 
\end{problem}

\begin{problem}
    11.2 Show that if $\lambda_2(G)$ has an algebraic multiplicity m in in the graph G, then adding up to m edges will not improve it. 

    If $\lambda_2 (G)$ has an algebraic multiplicity of m, there are m linearly independant eigenvectors assosicated with this $\lambda_2(G)$. Also the characteristic equation for this eigenvalues is 
    \begin{align*}
        f(\lambda) = (\lambda_1 -\lambda)(\lambda_2 - \lambda) \cdots (\lambda_{m+1} - \lambda) \cdots (\lambda_n - \lambda) = 0
    \end{align*}
    where $\lambda_2 = \lambda_3 = \cdots = \lambda_{m+1}$. If single edge is added, the connectivity increases, and increases the value of $\lambda_2$. However, the eigenvectors assosicated with those $\lambda$s are linearly independant, and therefore the value of $\lambda_3, \lambda_4 \cdots \lambda_m$ remains the same, making the second smallest eigenvalue to become $\lambda_3, \lambda_4 \cdots \lambda_{m+1}$. Therefore adding edges upto m edges would not change the value of second smallest eigenvalue.  
\end{problem}
\begin{problem}
    11.10 Use the approach of section11.6 and a semideÔ¨Ånite programming
    solver (such as the one mentioned in notes and references), to maximize
    $\lambda_2 (G)$ for the weighted versions of K5 , P5 , and S5 , subject to a normalization on the sum of the weights. Comment on any observed patterns for the
    optimal weight distribution.
    \begin{figure*}[!h]
        \centering
        \begin{subfigure}{0.45\textwidth}
            \includegraphics[width=\textwidth]{./img/p5_complete.png}
            \caption{$K_5$ weight distribution}
        \end{subfigure}
        \begin{subfigure}{0.45\textwidth}
            \includegraphics[width=\textwidth]{./img/p5_path.png}
            \caption{$P_5$ weight distribution}
        \end{subfigure}
        \begin{subfigure}{0.45\textwidth}
            \includegraphics[width=\textwidth]{./img/p5_star.png}
            \caption{$S_5$ weight distribution}
        \end{subfigure}
        \begin{subfigure}{0.45\textwidth}
            \includegraphics[width=\textwidth]{./img/p5_textbook.png}
            \caption{Textbook example }
        \end{subfigure}
    \end{figure*}

    We see that those weight are summed to 1 for all graphs and they are symmetric respect to their edges, in case of $K_5, P_5, S_5$. Of course the custom graph(textbook example) would not have symmetric weights for edges that are not symmetric. But the edge connecting (0,1) and (0,2) are symmetric and their weights are the same.
\end{problem}
\newpage
\section*{Code P3}
\begin{minted}{python3}

import networkx as nx
import matplotlib.pyplot as plt
import numpy as np
from scipy.integrate import odeint

def show(graph): 
    plt.figure()
    poses = nx.get_node_attributes(graph, 'pos')
    nx.draw_networkx_edges(graph, pos = poses,edgelist=graph.edges(),arrows=True)
    nx.draw_networkx_nodes(graph, pos = poses, nodelist=graph.nodes() ,label=True)
    nx.draw_networkx_labels(graph, pos=poses)
    plt.show()

def random_graphs_init(graph,num, Delta):
    poses = {i: np.random.randint(0,Delta) for i in range(num)} # starts inside Delta
    # poses = {i: np.random.randint(0,10*Delta) for i in range(num)} # starts outside of Delta
    # poses_= []
    # for i in range(num):
    #     if i == num -1:
    #         poses_.append(np.max(poses_) + Delta +10)
    #     else :
    #         poses_.append(np.random.randint(0,Delta))
    # poses = {i: poses_[i] for i in range(num)} # one element just outside of Delta
    nx.set_node_attributes(graph,poses, "pos")
    edges = {edge: np.abs(graph.nodes[edge[0]]["pos"]-graph.nodes[edge[1]]["pos"])  for edge in graph.edges()}
    desired_l = 0
    nx.set_edge_attributes(graph, edges, "edge_length")
    
    return graph, desired_l
num = 5
k = 1
Delta = 10
labels = []
D = nx.gnm_random_graph(num, (num -1)*(num-2)/2, directed=False)
D,desired_l = random_graphs_init(D,num, Delta)
D = nx.minimum_spanning_tree(D)

def xdot(x, t,desired_l):
    poses = {i: x[i] for i in range(num)}
    nx.set_node_attributes(D, poses, "pos")
    edges = {edge: np.abs(D.nodes[edge[1]]["pos"]-D.nodes[edge[0]]["pos"])  for edge in D.edges()}
    nx.set_edge_attributes(D, edges, "edge_length")
    ret  = []
    for i in range(num):
        dotx = 0
        for j in nx.neighbors(D, i):
            if ((i,j) in edges) :
                numerator = 2*(Delta - np.abs(desired_l )) - np.abs(edges[(i,j)] - desired_l )
                denominator = (Delta - np.abs(desired_l ) - np.abs(edges[(i,j)] - desired_l ))**2
                rest = D.nodes[i]["pos"] - D.nodes[j]["pos"] - desired_l 
                dotx += numerator/denominator *rest
            elif ((j,i) in edges):
                numerator = 2*(Delta - np.abs(desired_l )) - np.abs(edges[(j,i)] - desired_l )
                denominator = (Delta - np.abs(desired_l ) - np.abs(edges[(j,i)] - desired_l ))**2
                rest = D.nodes[i]["pos"] - D.nodes[j]["pos"] - desired_l 
                dotx += numerator/denominator *rest
        ret.append(-dotx)

    return ret

def main():
    
    for i in range(num):
        labels.append(f"x{i}")
    t = np.linspace(0, 40,num= 1001)
    
    l=[]
    [l.extend([v]) for k,v in nx.get_node_attributes(D, 'pos').items()]

    trajectory_x = odeint(xdot, l, t, args=(desired_l, ))
    plt.figure()
    plt.plot(t, trajectory_x, label = labels)

    plt.xlabel("Time t")
    plt.ylabel("Position")
    plt.title("one element just outside of Delta")
    plt.legend()
    plt.show()

if __name__ == "__main__":
    main()
    
\end{minted}
\section*{Code P5}
\begin{minted}{python3}
import cvxpy as cp
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
import numpy as np
#https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process
def gramschmidt(V):
    n, m = V.shape
    U = np.zeros_like(V)
    U[:, 0] = V[:, 0] / np.linalg.norm(V[:, 0])
    for i in range(1, m):
        U[:, i] = V[:, i]
        for j in range(i):
            U[:, i] -= np.dot(U[:, j].T, U[:, i]) * U[:, j]
        U[:, i] /= np.linalg.norm(U[:, i])
    return U[:,1:]

def main():
    nums = [5]
    custom_graph = nx.star_graph(nums[0]-2)
    custom_graph.add_node(nums[0] -1)
    custom_graph.add_edge(nums[0]-1, nums[0]-2)
    for num in nums:
        names = ['complete', 'path', 'star', 'custom' ]
        # graphs = [ custom_graph]
        graphs = [ nx.complete_graph(num), nx.path_graph(num), nx.star_graph(num - 1),custom_graph]
        k =0
        for graph in graphs:
            U = gramschmidt(np.column_stack([np.ones(num), np.random.randn(num, num-1)]))
            x = cp.Variable((len(graph.edges),len(graph.edges)), diag=True)
            D_D = nx.incidence_matrix(graph, graph.nodes(),oriented=True).toarray()
            gamma = cp.Variable(1)
            objective = cp.Maximize(gamma)
            constraints = [x >>0, cp.trace(x) == 1,(U.T@D_D @ x @ D_D.T@U )>>gamma*np.eye(num-1)]
            prob = cp.Problem(objective, constraints)
            result = prob.solve()
            plt.figure()
            plt.title(f"{names[k]} graph weight distribution")
            edges = list(graph.edges())
            edge_labels = [ '%.4f' % elem for elem in x.value.data[0] ]
            weight = {edges[i]: edge_labels[i] for i in range(len(edges))}
            pos = nx.spring_layout(graph)
            nx.draw(graph,pos = pos, with_labels = True)            
            nx.draw_networkx_edge_labels(graph, pos = pos, edge_labels=weight)
            k +=1
        plt.show()

if __name__ == "__main__":
    main()


\end{minted}
\end{document}